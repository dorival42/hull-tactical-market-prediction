
# üéØ HULL TACTICAL - MARKET PREDICTION
## Analyse Compl√®te du Challenge Kaggle

**Date de l'analyse :** 7 Novembre 2025  
**Participant :** 
- Pierre Chrislin DORIVAL
- Emile STEEVENSON
- Jobed FELIMA
- Sebastien Witchmen ESTANIS
  

---

## üìã TABLE DES MATI√àRES

1. [Vue d'ensemble](#vue-densemble)
2. [Structure des fichiers](#structure-des-fichiers)
3. [Description des donn√©es](#description-des-donn√©es)
4. [Architecture de l'API](#architecture-de-lapi)
5. [M√©thodologie de soumission](#m√©thodologie-de-soumission)
6. [Strat√©gie recommand√©e](#strat√©gie-recommand√©e)

---

## üéØ VUE D'ENSEMBLE

### Objectif du Challenge

Pr√©dire les **rendements exc√©dentaires du S&P 500** (`market_forward_excess_returns`) tout en respectant une **contrainte de volatilit√© de 120%**.

### D√©fi intellectuel

Remettre en question l'**Hypoth√®se des March√©s Efficaces (EMH)** qui stipule qu'il est impossible de battre le march√© de mani√®re syst√©matique.

### R√©compenses

- **Prize Pool** : $100,000
- **Timeline** :
  - Phase d'entra√Ænement : 16 sept - 15 d√©c 2025
  - Phase de forecasting : 15 d√©c 2025 - 16 juin 2026

### Particularit√© unique

Contrairement √† la plupart des comp√©titions Kaggle, Nos mod√®les seront **ex√©cut√©s en temps r√©el** sur le march√© pendant 6 mois apr√®s la deadline de soumission.

---

## üìÅ STRUCTURE DES FICHIERS

```
hull-tactical-market-prediction/
‚îÇ
‚îú‚îÄ‚îÄ train.csv                    # 8,991 lignes (d√©cennies de donn√©es historiques)
‚îú‚îÄ‚îÄ test.csv                     # 11 lignes (mock test set)
‚îÇ
‚îî‚îÄ‚îÄ kaggle_evaluation/           # API d'√©valuation
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ default_gateway.py       # Gateway par d√©faut
    ‚îú‚îÄ‚îÄ default_inference_server.py  # Serveur d'inf√©rence
    ‚îÇ
    ‚îî‚îÄ‚îÄ core/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ base_gateway.py      # Impl√©mentation de base
        ‚îú‚îÄ‚îÄ templates.py         # Templates pour Gateway et InferenceServer
        ‚îú‚îÄ‚îÄ relay.py             # Communication gRPC
        ‚îú‚îÄ‚îÄ kaggle_evaluation.proto
        ‚îÇ
        ‚îî‚îÄ‚îÄ generated/
            ‚îú‚îÄ‚îÄ __init__.py
            ‚îú‚îÄ‚îÄ kaggle_evaluation_pb2.py
            ‚îî‚îÄ‚îÄ kaggle_evaluation_pb2_grpc.py
```

---

## üìä DESCRIPTION DES DONN√âES

### TRAIN.CSV (8,991 lignes √ó 98 colonnes)

#### üîë Identifiant
- `date_id` : Identifiant unique pour chaque jour de trading (0 √† 8990)

#### üìà FEATURES (95 colonnes de variables pr√©dictives)

| Cat√©gorie | Pr√©fixe | Nombre | Description |
|-----------|---------|--------|-------------|
| **Dummy/Binary** | `D*` | 9 | Variables binaires/cat√©gorielles (D1-D9) |
| **Macro Economic** | `E*` | 20 | Indicateurs macro-√©conomiques (E1-E20) |
| **Interest Rate** | `I*` | 9 | Taux d'int√©r√™t (I1-I9) |
| **Market Dynamics** | `M*` | 18 | Dynamiques de march√© (M1-M18) |
| **Price/Valuation** | `P*` | 13 | Prix et valorisation (P1-P13) |
| **Sentiment** | `S*` | 12 | Indicateurs de sentiment (S1-S12) |
| **Volatility** | `V*` | 13 | Indicateurs de volatilit√© (V1-V13) |
| **Momentum** | `MOM*` | 1 | Indicateur de momentum |

**‚ö†Ô∏è IMPORTANT** : Les premi√®res ann√©es contiennent de **nombreuses valeurs manquantes** (coverage incomplet dans les donn√©es anciennes).

#### üéØ TARGETS (3 colonnes - TRAIN UNIQUEMENT)

1. **`forward_returns`**
   - Rendements obtenus en achetant le S&P 500 et en le vendant le lendemain
   - Formule : `(Prix_t+1 - Prix_t) / Prix_t`

2. **`risk_free_rate`**
   - Taux des fonds f√©d√©raux (Federal Funds Rate)
   - Utilis√© pour calculer les rendements exc√©dentaires

3. **`market_forward_excess_returns`** ‚≠ê **CIBLE PRINCIPALE**
   - Rendements exc√©dentaires par rapport aux attentes
   - **Calcul** :
     ```
     1. excess_returns = forward_returns - risk_free_rate
     2. mean_5y = moyenne mobile sur 5 ans de excess_returns
     3. deviation = excess_returns - mean_5y
     4. MAD = Median Absolute Deviation de deviation
     5. market_forward_excess_returns = winsorize(deviation, MAD √ó 4)
     ```
   - **C'est cette valeur que nous devons pr√©dire**

---

### TEST.CSV (11 lignes √ó 99 colonnes)

#### Structure pendant la phase d'entra√Ænement
- **Mock test set** : Copie des **180 derniers `date_id`** du train set (8811-8990)
- **10 lignes seulement** dans le fichier mock fourni

#### Colonnes suppl√©mentaires (par rapport au train)

| Colonne | Description |
|---------|-------------|
| **`is_scored`** | Indique si la ligne est incluse dans l'√©valuation |
| **`lagged_forward_returns`** | `forward_returns` avec 1 jour de retard |
| **`lagged_risk_free_rate`** | `risk_free_rate` avec 1 jour de retard |
| **`lagged_market_forward_excess_returns`** | `market_forward_excess_returns` avec 1 jour de retard |

**‚ö†Ô∏è Pourquoi le lag ?**  
Simule la r√©alit√© : nous ne connaissons les rendements qu'**apr√®s la cl√¥ture** du march√©. Cela √©vite le "look-ahead bias".

---

## üîÑ PHASES DE LA COMP√âTITION

### Phase 1 : Model Training (16 sept - 15 d√©c 2025)

```
TRAIN SET
‚îú‚îÄ‚îÄ Date IDs: 0 ‚Üí 8990
‚îú‚îÄ‚îÄ Features: D*, E*, I*, M*, P*, S*, V*, MOM*
‚îî‚îÄ‚îÄ Targets: forward_returns, risk_free_rate, market_forward_excess_returns

TEST SET (Mock)
‚îú‚îÄ‚îÄ Date IDs: 8811 ‚Üí 8990 (copie des derniers 180 jours du train)
‚îú‚îÄ‚îÄ Features: Identiques au train
‚îú‚îÄ‚îÄ Lagged targets: Disponibles avec 1 jour de retard
‚îî‚îÄ‚îÄ is_scored: True pour tous les jours
```

**Public Leaderboard** : ‚ö†Ô∏è **NON SIGNIFICATIF** (donn√©es d√©j√† vues dans le train set)

---

### Phase 2 : Forecasting (15 d√©c 2025 - 16 juin 2026)

```
TEST SET (Real-time)
‚îú‚îÄ‚îÄ Nouvelles donn√©es du march√© servies progressivement
‚îú‚îÄ‚îÄ Vos notebooks s'ex√©cutent AUTOMATIQUEMENT chaque jour
‚îú‚îÄ‚îÄ is_scored: True uniquement pour les nouveaux jours de trading
‚îî‚îÄ‚îÄ Dur√©e: ~6 mois = ~180 jours de trading
```

**Private Leaderboard** : Calcul√© sur les vraies pr√©dictions du march√© en temps r√©el.

---

## üèóÔ∏è ARCHITECTURE DE L'API

### Composants principaux

#### 1. **Gateway** (`default_gateway.py`)
- **R√¥le** : Coordonne l'√©valuation
- **Responsabilit√©s** :
  - Charger les donn√©es test
  - Envoyer les batches au serveur d'inf√©rence
  - Valider les pr√©dictions
  - G√©n√©rer le fichier de soumission

```python
class DefaultGateway(kaggle_evaluation.core.templates.Gateway):
    def generate_data_batches(self):
        # Lit test.csv
        # G√©n√®re des batches par date_id
        # Yield (test_batch, batch_id)
    
    def competition_specific_validation(self, prediction, row_ids, data_batch):
        # Validation sp√©cifique au challenge
        pass
```

#### 2. **InferenceServer** (`default_inference_server.py`)
- **R√¥le** : Notre code de pr√©diction
- **Responsabilit√©s** :
  - Recevoir les batches de donn√©es
  - G√©n√©rer les pr√©dictions
  - Retourner les allocations (0.0 √† 2.0)

```python
class DefaultInferenceServer(kaggle_evaluation.core.templates.InferenceServer):
    def predict(self, test_batch):
        # Notre  CODE ICI
        # Retourner une allocation entre 0.0 et 2.0
        return allocation
```

#### 3. **Communication gRPC**
- Utilise Protocol Buffers pour la communication
- Permet l'√©change de DataFrames entre Gateway et InferenceServer

---

## üì§ M√âTHODOLOGIE DE SOUMISSION

### Ce que nous devons soumettre

**UN NOTEBOOK** qui :
1. D√©finit une fonction `predict(test_batch)`
2. Cr√©e un `InferenceServer` avec cette fonction
3. D√©marre le serveur avec `server.serve()`

### Format de la pr√©diction

Pour chaque `date_id`, retourner une **allocation** :

| Valeur | Signification |
|--------|---------------|
| **0.0** | 0% expos√© au march√© (cash) |
| **0.5** | 50% expos√© |
| **1.0** | 100% expos√© (position standard) |
| **1.5** | 150% expos√© (levier) |
| **2.0** | 200% expos√© (levier maximal autoris√©) |

### Exemple minimal

```python
from kaggle_evaluation import default_inference_server

def predict(test_batch):
    """
    Args:
        test_batch: DataFrame avec les features pour un date_id
    
    Returns:
        float ou Series: Allocation entre 0.0 et 2.0
    """
    # Notre mod√®le de pr√©diction
    prediction = model.predict(test_batch)
    
    # Convertir en allocation (0.0 √† 2.0)
    allocation = convert_to_allocation(prediction)
    
    return allocation

# Cr√©er le serveur avec notre fonction predict
inference_server = default_inference_server.DefaultInferenceServer(predict)

# Tester localement
inference_server.run_local_gateway()

# Pour la soumission Kaggle
inference_server.serve()
```

---

## üìè M√âTRIQUE D'√âVALUATION

### Sharpe Ratio Modifi√© avec Contraintes

La m√©trique est une **variante du Sharpe Ratio** qui p√©nalise :

1. **Volatilit√© excessive** : > 120% de la volatilit√© du march√©
2. **Sous-performance** : Ne pas surperformer le rendement du march√©

### Formule (conceptuelle)

```
Score = (Rendement_strat√©gie - Rendement_march√©) / Volatilit√©_strat√©gie

Avec p√©nalit√©s si :
- Volatilit√©_strat√©gie > 1.2 √ó Volatilit√©_march√©
- Rendement_strat√©gie < Rendement_march√©
```

**Le code exact de la m√©trique est disponible sur Kaggle.**

---

## üéØ STRAT√âGIE RECOMMAND√âE

### 1. Exploration des Donn√©es (EDA)

#### A. Analyse temporelle
```python
import pandas as pd
import matplotlib.pyplot as plt

# Charger les donn√©es
train = pd.read_csv('train.csv')

# Analyser la couverture des features dans le temps
missing_by_date = train.isnull().sum(axis=1)
plt.plot(train['date_id'], missing_by_date)
plt.title('Valeurs manquantes par date')
plt.show()

# Analyser la distribution de la target
train['market_forward_excess_returns'].hist(bins=100)
plt.title('Distribution des rendements exc√©dentaires')
plt.show()
```

#### B. Analyse des features par cat√©gorie
```python
# Grouper par cat√©gorie
D_features = [col for col in train.columns if col.startswith('D')]
E_features = [col for col in train.columns if col.startswith('E')]
# ... etc

# Analyser les corr√©lations
correlation_with_target = train[E_features + ['market_forward_excess_returns']].corr()['market_forward_excess_returns']
print(correlation_with_target.sort_values(ascending=False))
```

---

### 2. Feature Engineering

#### A. Gestion des valeurs manquantes
```python
# Strat√©gies possibles :
# 1. Limiter l'analyse aux ann√©es r√©centes (moins de missing)
# 2. Forward fill pour certaines features (prix, taux)
# 3. Mod√®les robustes aux missing (LightGBM, CatBoost)
```

#### B. Features d√©riv√©es
```python
# Lag features
for lag in [1, 5, 10, 20]:
    train[f'forward_returns_lag_{lag}'] = train['forward_returns'].shift(lag)

# Rolling statistics
for window in [5, 10, 20, 60]:
    train[f'volatility_{window}d'] = train['forward_returns'].rolling(window).std()
    train[f'mean_return_{window}d'] = train['forward_returns'].rolling(window).mean()

# Momentum indicators
train['momentum_5_20'] = (
    train['forward_returns'].rolling(5).mean() - 
    train['forward_returns'].rolling(20).mean()
)
```

---

### 3. Mod√©lisation

#### A. Baseline simple
```python
# Strat√©gie 1 : Allocation constante
def baseline_constant(test_batch):
    return 1.0  # Toujours 100% investi

# Strat√©gie 2 : Bas√©e sur la volatilit√© r√©cente
def baseline_volatility(test_batch):
    recent_vol = test_batch['V1'].iloc[0]  # Exemple
    if recent_vol > threshold_high:
        return 0.5  # R√©duire l'exposition
    else:
        return 1.5  # Augmenter l'exposition
```

#### B. Mod√®les ML

**Option 1 : R√©gression directe**
```python
from sklearn.ensemble import RandomForestRegressor
import lightgbm as lgb

# Pr√©dire directement market_forward_excess_returns
model = lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=5
)

# Features s√©lectionn√©es
features = D_features + E_features + I_features + ['lagged_forward_returns']

# Entra√Æner
model.fit(train[features], train['market_forward_excess_returns'])

# Convertir pr√©diction en allocation
def predict(test_batch):
    pred_return = model.predict(test_batch[features])
    
    # Strat√©gie d'allocation bas√©e sur la pr√©diction
    if pred_return > 0.005:
        allocation = 1.5  # Bullish
    elif pred_return < -0.005:
        allocation = 0.3  # Bearish
    else:
        allocation = 1.0  # Neutre
    
    return allocation
```

**Option 2 : Classification (Bear/Bull/Neutral)**
```python
from sklearn.ensemble import GradientBoostingClassifier

# Cr√©er des classes
train['signal'] = pd.cut(
    train['market_forward_excess_returns'],
    bins=[-np.inf, -0.003, 0.003, np.inf],
    labels=['bear', 'neutral', 'bull']
)

# Mod√®le de classification
model = GradientBoostingClassifier()
model.fit(train[features], train['signal'])

# Allocation bas√©e sur la classe pr√©dite
def predict(test_batch):
    signal = model.predict(test_batch[features])[0]
    
    allocation_map = {
        'bear': 0.2,
        'neutral': 1.0,
        'bull': 1.8
    }
    
    return allocation_map[signal]
```

---

### 4. Gestion du Risque (Contrainte de volatilit√©)

```python
def predict_with_risk_management(test_batch, model, max_vol_ratio=1.2):
    # Pr√©diction brute
    raw_allocation = model.predict(test_batch)
    
    # Estimer la volatilit√© anticip√©e
    estimated_vol = estimate_volatility(test_batch)
    market_vol = test_batch['V1'].iloc[0]  # Exemple
    
    # Ajuster si n√©cessaire
    if estimated_vol > max_vol_ratio * market_vol:
        # R√©duire l'allocation pour respecter la contrainte
        scaling_factor = (max_vol_ratio * market_vol) / estimated_vol
        adjusted_allocation = raw_allocation * scaling_factor
    else:
        adjusted_allocation = raw_allocation
    
    # Assurer que l'allocation reste dans [0, 2]
    return np.clip(adjusted_allocation, 0.0, 2.0)
```

---

### 5. Validation

#### A. Walk-forward validation
```python
# Ne jamais entra√Æner sur des donn√©es futures
# Simuler le processus de pr√©diction jour par jour

results = []
for i in range(train_size, len(train)):
    # Train sur donn√©es pass√©es uniquement
    train_window = train.iloc[max(0, i-lookback):i]
    test_day = train.iloc[i:i+1]
    
    # Entra√Æner le mod√®le
    model.fit(train_window[features], train_window['target'])
    
    # Pr√©dire
    prediction = model.predict(test_day[features])
    results.append(prediction)
```

#### B. Calcul du Sharpe ratio
```python
def calculate_sharpe(allocations, returns, risk_free_rates):
    # Portfolio returns
    portfolio_returns = allocations * returns
    
    # Excess returns
    excess_returns = portfolio_returns - risk_free_rates
    
    # Sharpe ratio
    sharpe = excess_returns.mean() / excess_returns.std()
    
    return sharpe
```

---

### 6. Test Local avec l'API

```python
from kaggle_evaluation import default_inference_server

# Votre fonction de pr√©diction
def predict(test_batch):
    # Votre code ici
    return allocation

# Cr√©er le serveur
inference_server = default_inference_server.DefaultInferenceServer(predict)

# Tester localement sur le mock test set
inference_server.run_local_gateway()

# V√©rifier submission.parquet
import pandas as pd
submission = pd.read_parquet('submission.parquet')
print(submission.head())
```

---

## üé≤ APPROCHES AVANC√âES

### 1. Ensemble de mod√®les
```python
# Combiner plusieurs mod√®les
predictions = []
predictions.append(model_lgb.predict(test_batch) * 0.4)
predictions.append(model_xgb.predict(test_batch) * 0.3)
predictions.append(model_rf.predict(test_batch) * 0.3)

final_prediction = sum(predictions)
```

### 2. Mod√®les de s√©ries temporelles
```python
from statsmodels.tsa.arima.model import ARIMA
# ARIMA, GARCH pour la volatilit√©
```

### 3. Deep Learning
```python
import torch
import torch.nn as nn

class MarketPredictor(nn.Module):
    def __init__(self, input_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size, 128, 2, batch_first=True)
        self.fc = nn.Linear(128, 1)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])
```

---

## ‚ö†Ô∏è PI√àGES √Ä √âVITER

### 1. Look-ahead bias
‚ùå **NE JAMAIS** utiliser des informations futures pour entra√Æner le mod√®le

### 2. Overfitting sur le public leaderboard
‚ùå Le public leaderboard n'est **pas significatif** (mock data)
‚úÖ Se concentrer sur une validation walk-forward robuste

### 3. Ignorer la contrainte de volatilit√©
‚ùå Un mod√®le tr√®s performant mais trop volatil sera p√©nalis√©
‚úÖ Toujours v√©rifier que `Volatilit√©_strat√©gie ‚â§ 1.2 √ó Volatilit√©_march√©`

### 4. Ne pas g√©rer les valeurs manquantes
‚ùå Les premi√®res ann√©es ont beaucoup de missing values
‚úÖ Soit les ignorer, soit les imputer intelligemment

### 5. Strat√©gies trop complexes
‚ùå Mod√®les avec des centaines de features peuvent mal g√©n√©raliser
‚úÖ Commencer simple, ajouter de la complexit√© progressivement

---

## üìù CHECKLIST AVANT SOUMISSION

- [ ] Le mod√®le s'ex√©cute sans erreur sur le test set local
- [ ] La fonction `predict()` retourne des valeurs entre 0.0 et 2.0
- [ ] Le notebook d√©marre le serveur avec `inference_server.serve()`
- [ ] Le temps de startup est < 5 minutes (limite Kaggle)
- [ ] La pr√©diction par batch prend < 5 minutes (timeout)
- [ ] Le mod√®le a √©t√© valid√© avec walk-forward validation
- [ ] La contrainte de volatilit√© est respect√©e
- [ ] Les d√©pendances sont install√©es correctement
- [ ] Le code ne contient pas de look-ahead bias

---

## üöÄ  √âTAPES DU DEVELOPPEMLENT DU PROJET

### √âtape 1 : EDA Approfondie
1. Charger et explorer `train.csv`
2. Analyser les missing values par p√©riode
3. Visualiser la distribution de `market_forward_excess_returns`
4. √âtudier les corr√©lations entre features et target

### √âtape 2 : Baseline
1. Cr√©er une strat√©gie baseline simple
2. Tester avec l'API locale
3. Calculer le Sharpe ratio sur validation set

### √âtape 3 : Feature Engineering
1. Cr√©er des lag features
2. Calculer des rolling statistics
3. Ajouter des momentum indicators

### √âtape 4 : Mod√©lisation
1. Entra√Æner plusieurs mod√®les (LightGBM, XGBoost, RF)
2. Walk-forward validation
3. Optimiser les hyperparam√®tres

### √âtape 5 : Gestion du Risque
1. Impl√©menter la contrainte de volatilit√©
2. Tester diff√©rentes strat√©gies d'allocation
3. Valider le Sharpe ratio

### √âtape 6 : Soumission
1. Cr√©er le notebook de soumission
2. Tester localement avec l'API
3. Soumettre sur Kaggle
4. Surveiller les performances en temps r√©el

---

## üìö RESSOURCES

### Documentation Kaggle
- Page de la comp√©tition : https://www.kaggle.com/competitions/hull-tactical-market-prediction
- Notebook d'exemple : Disponible dans la section "Code"
- Forum de discussion : Pour poser des questions

### Concepts cl√©s
- Hypoth√®se des March√©s Efficaces (EMH)
- Sharpe Ratio
- Contrainte de volatilit√©
- Walk-forward validation
- Time series forecasting

### Librairies utiles
- `pandas`, `polars` : Manipulation de donn√©es
- `numpy` : Calculs num√©riques
- `scikit-learn` : ML classique
- `lightgbm`, `xgboost`, `catboost` : Boosting
- `statsmodels` : S√©ries temporelles
- `pytorch`, `tensorflow` : Deep learning

---

## üèÜ OBJECTIFS

### Court terme (1-2 semaines)
- [ ] Comprendre parfaitement les donn√©es
- [ ] Cr√©er une baseline fonctionnelle
- [ ] Soumettre une premi√®re version

### Moyen terme (1 mois)
- [ ] D√©velopper des features avanc√©es
- [ ] Optimiser le mod√®le
- [ ] Atteindre un Sharpe ratio > 1.0 en validation

### Long terme (jusqu'au 15 d√©c)
- [ ] Ensemble de mod√®les
- [ ] Strat√©gie de risk management robuste
- [ ] Viser le top 10% du leaderboard

---

**cette comp√©tition est passionnante, elle pourrait remettre en question l'une des th√©ories fondamentales de la finance moderne ! üöÄüìà**
** üöÄ Cest une atout pour notre future Carri√®re dans la Finance, Data science sur Machine learning **
