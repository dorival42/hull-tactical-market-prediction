"""
Script de test local COMPLET pour Hull Tactical
Simule le comportement du gateway Kaggle avec 3 modes de test
VERSION FINALE OPTIMIS√âE
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import polars as pl
import time
import traceback


def test_full_pipeline():
    """
    Test complet du pipeline avec le gateway local
    Simule exactement le comportement de Kaggle
    """
    
    print("=" * 80)
    print("TEST COMPLET AVEC GATEWAY LOCAL")
    print("=" * 80 + "\n")
    
    # 1. V√©rifier que les fichiers n√©cessaires existent
    print("1Ô∏è‚É£  V√âRIFICATION DES FICHIERS")
    print("-" * 80)
    
    required_files = [
        'test.csv',
        'xgb_model.pkl',
        'preprocessor.pkl',
        'default_inference_server.py'
    ]
    
    missing_files = []
    for file in required_files:
        if not Path(file).exists():
            missing_files.append(file)
            print(f"   ‚ùå Manquant: {file}")
        else:
            size_mb = Path(file).stat().st_size / (1024 * 1024)
            print(f"   ‚úì Trouv√©: {file} ({size_mb:.2f} MB)")
    
    if missing_files:
        print(f"\n‚ùå Fichiers manquants: {', '.join(missing_files)}")
        print("\nüí° Actions requises:")
        if 'xgb_model.pkl' in missing_files or 'preprocessor.pkl' in missing_files:
            print("  1. Ex√©cutez d'abord: python baseline_model.py")
        if 'test.csv' in missing_files:
            print("  2. T√©l√©chargez les donn√©es: kaggle competitions download -c hull-tactical-market-prediction")
        if 'default_inference_server.py' in missing_files:
            print("  3. Assurez-vous que default_inference_server.py existe")
        return False
    
    print("\n‚úÖ Tous les fichiers n√©cessaires sont pr√©sents\n")
    
    # 2. Importer l'InferenceServer
    print("2Ô∏è‚É£  INITIALISATION DE L'INFERENCE SERVER")
    print("-" * 80)
    
    try:
        from default_inference_server import DefaultInferenceServer
    except ImportError as e:
        print(f"‚ùå ERREUR lors de l'import de DefaultInferenceServer: {e}")
        print("\nüí° V√©rifiez que default_inference_server.py est dans le m√™me dossier")
        return False
    
    try:
        inference_server = DefaultInferenceServer()
    except Exception as e:
        print(f"‚ùå ERREUR lors de l'initialisation: {e}")
        traceback.print_exc()
        return False
    
    print("\n‚úÖ InferenceServer initialis√© avec succ√®s\n")
    
    # 3. Ex√©cuter le gateway local
    print("3Ô∏è‚É£  EX√âCUTION DU GATEWAY LOCAL")
    print("-" * 80)
    print("   (Cela va traiter tous les batches du test.csv)\n")
    
    start_time = time.time()
    
    try:
        # Le gateway va appeler votre fonction predict() pour chaque batch
        data_paths = (str(Path.cwd()),)  # Dossier actuel
        inference_server.run_local_gateway(data_paths=data_paths)
        
    except Exception as e:
        print(f"\n‚ùå ERREUR lors de l'ex√©cution du gateway: {e}")
        traceback.print_exc()
        return False
    
    elapsed_time = time.time() - start_time
    
    # 4. Afficher le r√©sum√©
    inference_server.print_summary()
    
    print("=" * 80)
    print("‚úÖ TEST COMPLET R√âUSSI !")
    print("=" * 80)
    print(f"‚è±Ô∏è  Temps total: {elapsed_time:.2f}s ({elapsed_time/60:.1f} min)")
    
    if elapsed_time > 3600:
        print(f"\n‚ö†Ô∏è  WARNING: Temps > 1 heure. Risque de timeout sur Kaggle.")
    elif elapsed_time > 1800:
        print(f"\n‚ö†Ô∏è  Temps √©lev√© ({elapsed_time/60:.1f} min). Optimisation recommand√©e.")
    else:
        print(f"\n‚úÖ Temps OK pour Kaggle")
    
    return True


def test_single_batch():
    """
    Test simple sur un seul batch
    Plus rapide pour le debugging
    """
    
    print("=" * 80)
    print("TEST RAPIDE - SINGLE BATCH")
    print("=" * 80 + "\n")
    
    # 1. V√©rifier les fichiers essentiels
    print("1Ô∏è‚É£  V√âRIFICATION DES FICHIERS")
    print("-" * 80)
    
    essential_files = ['test.csv', 'xgb_model.pkl', 'preprocessor.pkl']
    
    for file in essential_files:
        if not Path(file).exists():
            print(f"   ‚ùå Manquant: {file}")
            print(f"\n‚ùå Ex√©cutez d'abord: python baseline_model.py")
            return False
        else:
            print(f"   ‚úì {file}")
    
    print("\n‚úÖ Fichiers essentiels pr√©sents\n")
    
    # 2. Cr√©er l'InferenceServer
    print("2Ô∏è‚É£  INITIALISATION")
    print("-" * 80)
    
    try:
        from default_inference_server import DefaultInferenceServer
        inference_server = DefaultInferenceServer()
    except Exception as e:
        print(f"‚ùå ERREUR: {e}")
        traceback.print_exc()
        return False
    
    print("\n‚úÖ Initialisation r√©ussie\n")
    
    # 3. Charger un √©chantillon de test
    print("3Ô∏è‚É£  CHARGEMENT DE test.csv")
    print("-" * 80)
    
    test = pd.read_csv('test.csv')
    print(f"   Shape: {test.shape}")
    print(f"   Colonnes: {test.columns.tolist()[:10]}...")  # Afficher les 10 premi√®res
    
    # 4. Identifier les batch_ids (ou date_ids)
    if 'batch_id' in test.columns:
        batch_col = 'batch_id'
    elif 'date_id' in test.columns:
        batch_col = 'date_id'
    else:
        batch_col = test.columns[0]
    
    print(f"\n   Colonne de batch: {batch_col}")
    
    batch_ids = test[batch_col].unique()
    print(f"   Nombre de batches: {len(batch_ids)}")
    print(f"   Batch IDs: {batch_ids.tolist()}")
    
    if len(batch_ids) == 0:
        print("\n‚ùå Aucun batch trouv√© dans test.csv")
        return False
    
    # 5. Tester sur le premier batch
    print(f"\n4Ô∏è‚É£  TEST SUR LE PREMIER BATCH ({batch_col}={batch_ids[0]})")
    print("-" * 80)
    
    first_batch_id = batch_ids[0]
    test_batch_df = test[test[batch_col] == first_batch_id]
    
    print(f"   Batch {first_batch_id}: {len(test_batch_df)} ligne(s)")
    print(f"   Colonnes: {len(test_batch_df.columns)}")
    
    # Afficher les colonnes importantes
    important_cols = [batch_col, 'is_scored']
    for col in important_cols:
        if col in test_batch_df.columns:
            values = test_batch_df[col].unique()
            print(f"   {col}: {values}")
    
    # Convertir en Polars (comme le fait le gateway)
    test_batch_polars = pl.from_pandas(test_batch_df)
    test_batch = (test_batch_polars,)
    
    # 6. Faire la pr√©diction
    print(f"\n5Ô∏è‚É£  PR√âDICTION")
    print("-" * 80 + "\n")
    
    try:
        start_time = time.time()
        predictions = inference_server._predict_batch(test_batch)
        elapsed_time = time.time() - start_time
        
        print(f"\n‚úÖ Pr√©dictions g√©n√©r√©es avec succ√®s !")
        print(f"‚è±Ô∏è  Temps: {elapsed_time:.3f}s")
        
        # Afficher les r√©sultats
        print(f"\n6Ô∏è‚É£  R√âSULTATS POUR BATCH {first_batch_id}")
        print("-" * 80)
        
        results = pd.DataFrame({
            batch_col: test_batch_df[batch_col].values,
            'prediction': predictions.values
        })
        
        print(results.to_string(index=False))
        
        print(f"\nüìä Statistiques:")
        print(f"   Min    : {predictions.min():.6f}")
        print(f"   Max    : {predictions.max():.6f}")
        print(f"   Mean   : {predictions.mean():.6f}")
        print(f"   Median : {predictions.median():.6f}")
        print(f"   Std    : {predictions.std():.6f}")
        
        # V√©rifications
        print(f"\nüîç Validations:")
        nan_count = predictions.isna().sum()
        print(f"   NaN: {nan_count} {'‚úÖ' if nan_count == 0 else '‚ö†Ô∏è'}")
        
        extreme_count = (predictions.abs() > 0.1).sum()
        print(f"   Valeurs extr√™mes (>|0.1|): {extreme_count} {'‚úÖ' if extreme_count == 0 else '‚ö†Ô∏è'}")
        
    except Exception as e:
        print(f"‚ùå ERREUR lors de la pr√©diction: {e}")
        traceback.print_exc()
        return False
    
    print("\n" + "=" * 80)
    print("‚úÖ TEST SINGLE BATCH R√âUSSI !")
    print("=" * 80)
    
    return True


def analyze_test_structure():
    """
    Analyser la structure de test.csv
    Utile pour comprendre les donn√©es avant de tester
    """
    
    print("=" * 80)
    print("ANALYSE DE TEST.CSV")
    print("=" * 80 + "\n")
    
    if not Path('test.csv').exists():
        print("‚ùå test.csv n'existe pas")
        print("\nüí° T√©l√©chargez les donn√©es:")
        print("   kaggle competitions download -c hull-tactical-market-prediction")
        return False
    
    # Charger les donn√©es
    print("üì• Chargement de test.csv...")
    test = pd.read_csv('test.csv')
    
    # Informations de base
    print(f"\nüìä INFORMATIONS G√âN√âRALES")
    print("-" * 80)
    print(f"Shape: {test.shape}")
    print(f"Taille: {Path('test.csv').stat().st_size / (1024*1024):.2f} MB")
    
    # Colonnes
    print(f"\nüìã COLONNES ({len(test.columns)})")
    print("-" * 80)
    
    # Grouper les colonnes par type
    col_groups = {}
    for col in test.columns:
        if col in ['date_id', 'is_scored']:
            prefix = 'Meta'
        elif col.startswith('lagged_'):
            prefix = 'Lagged'
        elif len(col) > 1 and col[0].isalpha() and col[1:].isdigit():
            prefix = col[0]
        else:
            prefix = 'Other'
        
        if prefix not in col_groups:
            col_groups[prefix] = []
        col_groups[prefix].append(col)
    
    for prefix in sorted(col_groups.keys()):
        cols = col_groups[prefix]
        print(f"   {prefix:8s}: {len(cols):3d} colonnes - {cols[:5]}...")
    
    # Identifier la colonne de batch
    print(f"\nüîë COLONNE DE BATCH")
    print("-" * 80)
    
    if 'batch_id' in test.columns:
        batch_col = 'batch_id'
    elif 'date_id' in test.columns:
        batch_col = 'date_id'
    else:
        batch_col = test.columns[0]
    
    print(f"   Colonne identifi√©e: {batch_col}")
    
    # Analyser les batches
    batch_ids = test[batch_col].unique()
    print(f"   Nombre de batches uniques: {len(batch_ids)}")
    print(f"   Batch IDs: {sorted(batch_ids.tolist())}")
    
    # Taille de chaque batch
    print(f"\nüì¶ TAILLE DES BATCHES")
    print("-" * 80)
    
    batch_sizes = test.groupby(batch_col).size()
    print(f"   Min: {batch_sizes.min()} lignes")
    print(f"   Max: {batch_sizes.max()} lignes")
    print(f"   Moyenne: {batch_sizes.mean():.1f} lignes")
    print(f"   Total: {batch_sizes.sum()} lignes")
    
    if len(batch_sizes) <= 20:
        print(f"\n   D√©tail par batch:")
        for batch_id, size in batch_sizes.items():
            print(f"      Batch {batch_id}: {size} ligne(s)")
    
    # Colonnes is_scored
    print(f"\nüéØ COLONNES SP√âCIALES")
    print("-" * 80)
    
    if 'is_scored' in test.columns:
        scored_count = test['is_scored'].sum()
        print(f"   is_scored: {scored_count}/{len(test)} lignes seront scor√©es")
        
        if scored_count < len(test):
            print(f"   ‚ö†Ô∏è  {len(test) - scored_count} lignes ne seront PAS scor√©es (public leaderboard)")
    else:
        print(f"   is_scored: Colonne absente")
    
    # Lagged features
    lagged_cols = [col for col in test.columns if col.startswith('lagged_')]
    if lagged_cols:
        print(f"\n   Lagged features ({len(lagged_cols)}):")
        for col in lagged_cols:
            print(f"      - {col}")
    
    # Types de donn√©es
    print(f"\nüìä TYPES DE DONN√âES")
    print("-" * 80)
    
    type_counts = test.dtypes.value_counts()
    for dtype, count in type_counts.items():
        print(f"   {str(dtype):12s}: {count:3d} colonnes")
    
    # Valeurs manquantes
    print(f"\n‚ùì VALEURS MANQUANTES")
    print("-" * 80)
    
    missing = test.isnull().sum()
    missing_cols = missing[missing > 0]
    
    if len(missing_cols) > 0:
        print(f"   {len(missing_cols)} colonnes avec des NaN:")
        
        # Afficher les 10 colonnes avec le plus de NaN
        top_missing = missing_cols.sort_values(ascending=False).head(10)
        for col, count in top_missing.items():
            pct = count / len(test) * 100
            print(f"      {col:30s}: {count:5d} ({pct:5.1f}%)")
        
        if len(missing_cols) > 10:
            print(f"      ... et {len(missing_cols) - 10} autres colonnes")
    else:
        print("   ‚úÖ Aucune valeur manquante")
    
    # Premi√®res lignes
    print(f"\nüìã PREMI√àRES LIGNES")
    print("-" * 80)
    print(test.head(3).to_string())
    
    # Statistiques descriptives (quelques colonnes)
    print(f"\nüìà STATISTIQUES (√©chantillon)")
    print("-" * 80)
    
    numeric_cols = test.select_dtypes(include=['number']).columns[:5]
    print(test[numeric_cols].describe().to_string())
    
    print("\n" + "=" * 80)
    print("‚úÖ ANALYSE TERMIN√âE")
    print("=" * 80)
    
    return True


def print_help():
    """Afficher l'aide d√©taill√©e"""
    
    print("\n" + "=" * 80)
    print("AIDE - TEST_LOCAL.PY")
    print("=" * 80)
    
    print("\nüìñ DESCRIPTION")
    print("-" * 80)
    print("   Script de test local pour Hull Tactical Market Prediction.")
    print("   Permet de tester l'InferenceServer avant la soumission Kaggle.")
    
    print("\nüéØ MODES DISPONIBLES")
    print("-" * 80)
    
    modes = [
        ("analyze", "Analyser la structure de test.csv", "Rapide", "D√©couvrir les donn√©es"),
        ("single", "Tester sur un seul batch", "Rapide", "Debugging rapide"),
        ("full", "Tester sur tous les batches", "Lent", "Simulation compl√®te Kaggle"),
    ]
    
    for mode, desc, speed, usage in modes:
        print(f"\n   {mode:10s} - {desc}")
        print(f"                Vitesse: {speed}")
        print(f"                Usage: {usage}")
    
    print("\nüìù EXEMPLES D'UTILISATION")
    print("-" * 80)
    print("   # Analyser test.csv")
    print("   python test_local.py --mode analyze")
    print()
    print("   # Test rapide (1 batch)")
    print("   python test_local.py --mode single")
    print()
    print("   # Test complet (tous les batches)")
    print("   python test_local.py --mode full")
    
    print("\nüìã WORKFLOW RECOMMAND√â")
    print("-" * 80)
    print("   1. python test_local.py --mode analyze")
    print("      ‚Üí Comprendre la structure des donn√©es")
    print()
    print("   2. python baseline_model.py")
    print("      ‚Üí Entra√Æner le mod√®le")
    print()
    print("   3. python test_local.py --mode single")
    print("      ‚Üí Test rapide du pipeline")
    print()
    print("   4. python test_local.py --mode full")
    print("      ‚Üí Validation compl√®te avant soumission")
    print()
    print("   5. [Soumettre √† Kaggle]")
    
    print("\nüí° PR√âREQUIS")
    print("-" * 80)
    print("   - test.csv (donn√©es Kaggle)")
    print("   - xgb_model.pkl (g√©n√©r√© par baseline_model.py)")
    print("   - preprocessor.pkl (g√©n√©r√© par baseline_model.py)")
    print("   - default_inference_server.py")
    
    print("\n" + "=" * 80 + "\n")


# ==============================================================================
# MAIN
# ==============================================================================

if __name__ == '__main__':
    
    # Parser les arguments
    parser = argparse.ArgumentParser(
        description='Tester l\'InferenceServer localement pour Hull Tactical',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python test_local.py --mode analyze    # Analyser test.csv
  python test_local.py --mode single     # Test rapide (1 batch)
  python test_local.py --mode full       # Test complet (tous les batches)
  python test_local.py --help            # Afficher l'aide d√©taill√©e
        """
    )
    
    parser.add_argument(
        '--mode',
        type=str,
        default='single',
        choices=['single', 'full', 'analyze', 'help'],
        help='Mode de test: single (rapide), full (complet), analyze (analyser test.csv), help (aide d√©taill√©e)'
    )
    
    args = parser.parse_args()
    
    # Ex√©cuter le mode choisi
    print("\n" + "üîç" * 40)
    print(f"MODE: {args.mode.upper()}")
    print("üîç" * 40 + "\n")
    
    success = False
    
    if args.mode == 'help':
        print_help()
        success = True
    
    elif args.mode == 'analyze':
        success = analyze_test_structure()
    
    elif args.mode == 'single':
        success = test_single_batch()
    
    elif args.mode == 'full':
        success = test_full_pipeline()
    
    else:
        print(f"‚ùå Mode inconnu: {args.mode}")
        print("   Utilisez --help pour voir les modes disponibles.")
        sys.exit(1)
    
    # Exit code
    if success:
        print("\nüí° PROCHAINES √âTAPES:")
        if args.mode == 'analyze':
            print("   1. Entra√Æner le mod√®le: python baseline_model.py")
            print("   2. Tester: python test_local.py --mode single")
        elif args.mode == 'single':
            print("   1. Test complet: python test_local.py --mode full")
            print("   2. Analyser: python analyze_results.py")
        elif args.mode == 'full':
            print("   1. Analyser: python analyze_results.py")
            print("   2. Si Sharpe > 0.5: SOUMETTRE √Ä KAGGLE ! üöÄ")
        
        sys.exit(0)
    else:
        print("\n‚ùå Des probl√®mes ont √©t√© d√©tect√©s.")
        print("   Corrigez-les avant de continuer.")
        sys.exit(1)