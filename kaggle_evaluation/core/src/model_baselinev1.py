"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HULL TACTICAL - BASELINE MODELS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ce script implÃ©mente plusieurs stratÃ©gies baseline :
1. Buy & Hold (allocation constante)
2. Momentum Simple
3. Volatility-based
4. LightGBM Baseline
5. XGBoost Baseline

Objectif : Ã‰tablir une performance de rÃ©fÃ©rence et calculer le Sharpe ratio

Auteur: Baseline Hull Tactical
Date: 7 Novembre 2025
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("HULL TACTICAL - BASELINE MODELS")
print("="*80)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("1. CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES")
print("="*80)

train = pd.read_csv('train.csv')
print(f"\nâœ“ DonnÃ©es chargÃ©es: {train.shape[0]:,} lignes Ã— {train.shape[1]} colonnes")

# Utiliser seulement les donnÃ©es rÃ©centes (moins de valeurs manquantes)
# BasÃ© sur l'EDA : date_id > 7000 a 0% de valeurs manquantes
CUTOFF_DATE = 7000
train_clean = train[train['date_id'] >= CUTOFF_DATE].copy()
print(f"âœ“ DonnÃ©es aprÃ¨s cutoff (date_id >= {CUTOFF_DATE}): {train_clean.shape[0]:,} lignes")

# VÃ©rifier les valeurs manquantes
missing_pct = (train_clean.isnull().sum().sum() / (train_clean.shape[0] * train_clean.shape[1]) * 100)
print(f"âœ“ Valeurs manquantes: {missing_pct:.2f}%")

# DÃ©finir les features et la target
target_col = 'market_forward_excess_returns'
exclude_cols = ['date_id', 'forward_returns', 'risk_free_rate', target_col]
feature_cols = [col for col in train_clean.columns if col not in exclude_cols]

print(f"\nğŸ“Š CONFIGURATION:")
print(f"   Target: {target_col}")
print(f"   Features: {len(feature_cols)}")
print(f"   PÃ©riode: date_id {train_clean['date_id'].min()} Ã  {train_clean['date_id'].max()}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. SPLIT TEMPOREL (WALK-FORWARD)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("2. SPLIT TEMPOREL (WALK-FORWARD VALIDATION)")
print("="*80)

# Split: 80% train, 20% validation
split_idx = int(len(train_clean) * 0.8)
train_df = train_clean.iloc[:split_idx].copy()
val_df = train_clean.iloc[split_idx:].copy()

print(f"\nğŸ“Š SPLIT DES DONNÃ‰ES:")
print(f"   Train set: {len(train_df):,} lignes (date_id {train_df['date_id'].min()}-{train_df['date_id'].max()})")
print(f"   Val set:   {len(val_df):,} lignes (date_id {val_df['date_id'].min()}-{val_df['date_id'].max()})")

# PrÃ©parer X et y
X_train = train_df[feature_cols]
y_train = train_df[target_col]
X_val = val_df[feature_cols]
y_val = val_df[target_col]

print(f"\nâœ“ Features prÃ©parÃ©es: {X_train.shape[1]} colonnes")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. FONCTION DE CALCUL DU SHARPE RATIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_sharpe_ratio(allocations, returns, risk_free_rates, max_volatility_ratio=1.2):
    """
    Calcule le Sharpe ratio avec contrainte de volatilitÃ©.
    
    Args:
        allocations: Array d'allocations (0-2)
        returns: Array de forward_returns
        risk_free_rates: Array de risk_free_rate
        max_volatility_ratio: Ratio maximal de volatilitÃ© autorisÃ© (dÃ©faut 1.2)
    
    Returns:
        dict avec sharpe_ratio, annualized_return, volatility, etc.
    """
    # Rendements du portefeuille
    portfolio_returns = allocations * returns
    
    # Rendements excÃ©dentaires
    excess_returns = portfolio_returns - risk_free_rates
    
    # Calculs
    mean_excess_return = excess_returns.mean()
    volatility = excess_returns.std()
    
    # Sharpe ratio (annualisÃ©, 252 jours de trading par an)
    sharpe_ratio = (mean_excess_return / volatility) * np.sqrt(252) if volatility > 0 else 0
    
    # Rendement annualisÃ©
    annualized_return = mean_excess_return * 252
    annualized_volatility = volatility * np.sqrt(252)
    
    # VolatilitÃ© du marchÃ© (pour la contrainte)
    market_volatility = returns.std()
    volatility_ratio = volatility / market_volatility if market_volatility > 0 else 0
    
    # PÃ©nalitÃ© si on dÃ©passe la contrainte de volatilitÃ©
    exceeds_volatility_constraint = volatility_ratio > max_volatility_ratio
    
    return {
        'sharpe_ratio': sharpe_ratio,
        'annualized_return': annualized_return,
        'annualized_volatility': annualized_volatility,
        'volatility_ratio': volatility_ratio,
        'exceeds_constraint': exceeds_volatility_constraint,
        'mean_allocation': allocations.mean(),
        'std_allocation': allocations.std()
    }

def convert_prediction_to_allocation(predictions, method='simple', threshold=0.003):
    """
    Convertit les prÃ©dictions en allocations (0-2).
    
    Args:
        predictions: Array de prÃ©dictions de rendements
        method: 'simple', 'proportional', 'threshold'
        threshold: Seuil pour la mÃ©thode 'threshold'
    
    Returns:
        Array d'allocations
    """
    if method == 'simple':
        # Simple: si positif -> 1.5, si nÃ©gatif -> 0.5
        allocations = np.where(predictions > 0, 1.5, 0.5)
    
    elif method == 'proportional':
        # Proportionnel: allocation basÃ©e sur la magnitude de la prÃ©diction
        # Normaliser entre 0 et 2
        min_pred = predictions.min()
        max_pred = predictions.max()
        if max_pred > min_pred:
            allocations = 0.2 + 1.6 * (predictions - min_pred) / (max_pred - min_pred)
        else:
            allocations = np.full_like(predictions, 1.0)
    
    elif method == 'threshold':
        # BasÃ© sur des seuils
        allocations = np.ones_like(predictions)  # DÃ©faut: 1.0
        allocations[predictions > threshold] = 1.8
        allocations[(predictions > 0) & (predictions <= threshold)] = 1.3
        allocations[(predictions < 0) & (predictions >= -threshold)] = 0.7
        allocations[predictions < -threshold] = 0.2
    
    # S'assurer que les allocations sont dans [0, 2]
    allocations = np.clip(allocations, 0.0, 2.0)
    
    return allocations

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. BASELINE 1: BUY & HOLD (ALLOCATION CONSTANTE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("4. BASELINE 1: BUY & HOLD (ALLOCATION CONSTANTE)")
print("="*80)

# Tester diffÃ©rentes allocations constantes
constant_allocations = [0.5, 1.0, 1.5, 2.0]
buy_hold_results = []

for allocation in constant_allocations:
    allocations = np.full(len(val_df), allocation)
    metrics = calculate_sharpe_ratio(
        allocations,
        val_df['forward_returns'].values,
        val_df['risk_free_rate'].values
    )
    buy_hold_results.append({
        'allocation': allocation,
        **metrics
    })
    
    print(f"\n   Allocation constante = {allocation:.1f}:")
    print(f"      Sharpe Ratio:      {metrics['sharpe_ratio']:+.4f}")
    print(f"      Annual Return:     {metrics['annualized_return']*100:+.2f}%")
    print(f"      Annual Volatility: {metrics['annualized_volatility']*100:.2f}%")
    print(f"      Volatility Ratio:  {metrics['volatility_ratio']:.2f}x")
    print(f"      Constraint OK:     {'NON âŒ' if metrics['exceeds_constraint'] else 'OUI âœ“'}")

# Meilleure allocation constante
best_buy_hold = max(buy_hold_results, key=lambda x: x['sharpe_ratio'])
print(f"\nğŸ† MEILLEURE ALLOCATION CONSTANTE: {best_buy_hold['allocation']:.1f}")
print(f"   Sharpe Ratio: {best_buy_hold['sharpe_ratio']:+.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. BASELINE 2: MOMENTUM SIMPLE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("5. BASELINE 2: MOMENTUM SIMPLE")
print("="*80)

# Calculer le momentum sur diffÃ©rentes fenÃªtres
windows = [5, 10, 20]
momentum_results = []

for window in windows:
    # Calculer le momentum
    val_df[f'momentum_{window}'] = val_df[target_col].rolling(window).mean()
    
    # StratÃ©gie: si momentum > 0 -> 1.5, sinon -> 0.5
    allocations = np.where(val_df[f'momentum_{window}'].values > 0, 1.5, 0.5)
    
    # GÃ©rer les NaN au dÃ©but
    valid_idx = ~np.isnan(allocations)
    
    if valid_idx.sum() > 0:
        metrics = calculate_sharpe_ratio(
            allocations[valid_idx],
            val_df['forward_returns'].values[valid_idx],
            val_df['risk_free_rate'].values[valid_idx]
        )
        momentum_results.append({
            'window': window,
            **metrics
        })
        
        print(f"\n   Momentum Window = {window} jours:")
        print(f"      Sharpe Ratio:      {metrics['sharpe_ratio']:+.4f}")
        print(f"      Annual Return:     {metrics['annualized_return']*100:+.2f}%")
        print(f"      Annual Volatility: {metrics['annualized_volatility']*100:.2f}%")
        print(f"      Volatility Ratio:  {metrics['volatility_ratio']:.2f}x")
        print(f"      Constraint OK:     {'NON âŒ' if metrics['exceeds_constraint'] else 'OUI âœ“'}")

# Meilleur momentum
best_momentum = max(momentum_results, key=lambda x: x['sharpe_ratio'])
print(f"\nğŸ† MEILLEUR MOMENTUM: Window = {best_momentum['window']} jours")
print(f"   Sharpe Ratio: {best_momentum['sharpe_ratio']:+.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. BASELINE 3: VOLATILITY-BASED
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("6. BASELINE 3: VOLATILITY-BASED")
print("="*80)

# StratÃ©gie: rÃ©duire l'allocation en pÃ©riode de haute volatilitÃ©
window = 20
val_df['rolling_vol'] = val_df['forward_returns'].rolling(window).std()

# Normaliser la volatilitÃ©
vol_mean = val_df['rolling_vol'].mean()
vol_std = val_df['rolling_vol'].std()

# Allocation inversement proportionnelle Ã  la volatilitÃ©
# Haute vol -> faible allocation, faible vol -> haute allocation
normalized_vol = (val_df['rolling_vol'] - vol_mean) / vol_std
allocations = 1.5 - 0.5 * normalized_vol  # Range: environ 0.5 Ã  2.0
allocations = np.clip(allocations, 0.2, 2.0)

# GÃ©rer les NaN
valid_idx = ~np.isnan(allocations)
metrics = calculate_sharpe_ratio(
    allocations[valid_idx],
    val_df['forward_returns'].values[valid_idx],
    val_df['risk_free_rate'].values[valid_idx]
)

print(f"\n   Volatility-Based (Window = {window} jours):")
print(f"      Sharpe Ratio:      {metrics['sharpe_ratio']:+.4f}")
print(f"      Annual Return:     {metrics['annualized_return']*100:+.2f}%")
print(f"      Annual Volatility: {metrics['annualized_volatility']*100:.2f}%")
print(f"      Volatility Ratio:  {metrics['volatility_ratio']:.2f}x")
print(f"      Mean Allocation:   {metrics['mean_allocation']:.2f}")
print(f"      Constraint OK:     {'NON âŒ' if metrics['exceeds_constraint'] else 'OUI âœ“'}")

volatility_sharpe = metrics['sharpe_ratio']

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. BASELINE 4: LIGHTGBM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("7. BASELINE 4: LIGHTGBM")
print("="*80)

print("\n   EntraÃ®nement du modÃ¨le LightGBM...")

# ParamÃ¨tres LightGBM
lgb_params = {
    'objective': 'regression',
    'metric': 'rmse',
    'verbosity': -1,
    'n_estimators': 300,
    'learning_rate': 0.05,
    'max_depth': 5,
    'num_leaves': 31,
    'min_child_samples': 20,
    'random_state': 42
}

# EntraÃ®ner le modÃ¨le
lgb_model = lgb.LGBMRegressor(**lgb_params)
lgb_model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]
)

# PrÃ©dictions
y_pred_lgb = lgb_model.predict(X_val)

# MÃ©triques de prÃ©diction
rmse_lgb = np.sqrt(mean_squared_error(y_val, y_pred_lgb))
mae_lgb = mean_absolute_error(y_val, y_pred_lgb)
r2_lgb = r2_score(y_val, y_pred_lgb)

print(f"\n   MÃ©triques de prÃ©diction:")
print(f"      RMSE: {rmse_lgb:.6f}")
print(f"      MAE:  {mae_lgb:.6f}")
print(f"      RÂ²:   {r2_lgb:.4f}")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': lgb_model.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\n   Top 10 features importantes:")
for i, row in feature_importance.head(10).iterrows():
    print(f"      {row['feature']:15s}: {row['importance']:8.2f}")

# Convertir en allocations (tester diffÃ©rentes mÃ©thodes)
allocation_methods = ['simple', 'proportional', 'threshold']
lgb_results = []

for method in allocation_methods:
    allocations = convert_prediction_to_allocation(y_pred_lgb, method=method)
    metrics = calculate_sharpe_ratio(
        allocations,
        val_df['forward_returns'].values,
        val_df['risk_free_rate'].values
    )
    lgb_results.append({
        'method': method,
        **metrics
    })
    
    print(f"\n   MÃ©thode d'allocation: '{method}'")
    print(f"      Sharpe Ratio:      {metrics['sharpe_ratio']:+.4f}")
    print(f"      Annual Return:     {metrics['annualized_return']*100:+.2f}%")
    print(f"      Annual Volatility: {metrics['annualized_volatility']*100:.2f}%")
    print(f"      Mean Allocation:   {metrics['mean_allocation']:.2f}")
    print(f"      Std Allocation:    {metrics['std_allocation']:.2f}")
    print(f"      Constraint OK:     {'NON âŒ' if metrics['exceeds_constraint'] else 'OUI âœ“'}")

# Meilleure mÃ©thode LightGBM
best_lgb = max(lgb_results, key=lambda x: x['sharpe_ratio'])
print(f"\nğŸ† MEILLEURE MÃ‰THODE LIGHTGBM: '{best_lgb['method']}'")
print(f"   Sharpe Ratio: {best_lgb['sharpe_ratio']:+.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. BASELINE 5: XGBOOST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("8. BASELINE 5: XGBOOST")
print("="*80)

print("\n   EntraÃ®nement du modÃ¨le XGBoost...")

# ParamÃ¨tres XGBoost
xgb_params = {
    'objective': 'reg:squarederror',
    'n_estimators': 300,
    'learning_rate': 0.05,
    'max_depth': 5,
    'min_child_weight': 3,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42,
    'verbosity': 0
}

# EntraÃ®ner le modÃ¨le
xgb_model = xgb.XGBRegressor(**xgb_params)
xgb_model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    verbose=False
)

# PrÃ©dictions
y_pred_xgb = xgb_model.predict(X_val)

# MÃ©triques de prÃ©diction
rmse_xgb = np.sqrt(mean_squared_error(y_val, y_pred_xgb))
mae_xgb = mean_absolute_error(y_val, y_pred_xgb)
r2_xgb = r2_score(y_val, y_pred_xgb)

print(f"\n   MÃ©triques de prÃ©diction:")
print(f"      RMSE: {rmse_xgb:.6f}")
print(f"      MAE:  {mae_xgb:.6f}")
print(f"      RÂ²:   {r2_xgb:.4f}")

# Convertir en allocations
xgb_results = []

for method in allocation_methods:
    allocations = convert_prediction_to_allocation(y_pred_xgb, method=method)
    metrics = calculate_sharpe_ratio(
        allocations,
        val_df['forward_returns'].values,
        val_df['risk_free_rate'].values
    )
    xgb_results.append({
        'method': method,
        **metrics
    })
    
    print(f"\n   MÃ©thode d'allocation: '{method}'")
    print(f"      Sharpe Ratio:      {metrics['sharpe_ratio']:+.4f}")
    print(f"      Annual Return:     {metrics['annualized_return']*100:+.2f}%")
    print(f"      Annual Volatility: {metrics['annualized_volatility']*100:.2f}%")
    print(f"      Mean Allocation:   {metrics['mean_allocation']:.2f}")
    print(f"      Constraint OK:     {'NON âŒ' if metrics['exceeds_constraint'] else 'OUI âœ“'}")

# Meilleure mÃ©thode XGBoost
best_xgb = max(xgb_results, key=lambda x: x['sharpe_ratio'])
print(f"\nğŸ† MEILLEURE MÃ‰THODE XGBOOST: '{best_xgb['method']}'")
print(f"   Sharpe Ratio: {best_xgb['sharpe_ratio']:+.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9. COMPARAISON FINALE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "="*80)
print("9. COMPARAISON FINALE DES BASELINES")
print("="*80)

# Compiler tous les rÃ©sultats
all_results = [
    {'strategy': f'Buy & Hold ({best_buy_hold["allocation"]:.1f})', **best_buy_hold},
    {'strategy': f'Momentum ({best_momentum["window"]}d)', **best_momentum},
    {'strategy': 'Volatility-Based', 'sharpe_ratio': volatility_sharpe, **metrics},
    {'strategy': f'LightGBM ({best_lgb["method"]})', **best_lgb},
    {'strategy': f'XGBoost ({best_xgb["method"]})', **best_xgb}
]

# Trier par Sharpe Ratio
all_results_sorted = sorted(all_results, key=lambda x: x['sharpe_ratio'], reverse=True)

print("\nğŸ“Š CLASSEMENT PAR SHARPE RATIO:\n")
print(f"{'Rang':<5} {'StratÃ©gie':<30} {'Sharpe':<10} {'Return':<10} {'Volatility':<12} {'Constraint':<10}")
print("-" * 80)

for i, result in enumerate(all_results_sorted, 1):
    strategy = result['strategy']
    sharpe = result['sharpe_ratio']
    ret = result['annualized_return'] * 100
    vol = result['annualized_volatility'] * 100
    constraint = 'âœ“ OK' if not result['exceeds_constraint'] else 'âŒ NON'
    
    print(f"{i:<5} {strategy:<30} {sharpe:+.4f}    {ret:+6.2f}%    {vol:6.2f}%      {constraint:<10}")

# Meilleure stratÃ©gie globale
best_overall = all_results_sorted[0]
print(f"\n{'='*80}")
print(f"ğŸ† MEILLEURE STRATÃ‰GIE BASELINE: {best_overall['strategy']}")
print(f"{'='*80}")
print(f"   Sharpe Ratio:        {best_overall['sharpe_ratio']:+.4f}")
print(f"   Rendement annualisÃ©: {best_overall['annualized_return']*100:+.2f}%")
print(f"   VolatilitÃ© annualisÃ©: {best_overall['annualized_volatility']*100:.2f}%")
print(f"   Ratio de volatilitÃ©:  {best_overall['volatility_ratio']:.2f}x")
print(f"   Respecte contrainte:  {'OUI âœ“' if not best_overall['exceeds_constraint'] else 'NON âŒ'}")

# Benchmark du marchÃ© (allocation = 1.0)
market_benchmark = [r for r in all_results if 'Buy & Hold (1.0)' in r['strategy']]
if market_benchmark:
    market_sharpe = market_benchmark[0]['sharpe_ratio']
    improvement = ((best_overall['sharpe_ratio'] - market_sharpe) / abs(market_sharpe) * 100) if market_sharpe != 0 else 0
    print(f"\nğŸ“ˆ AMÃ‰LIORATION VS MARCHÃ‰ (Buy & Hold 1.0):")
    print(f"   Market Sharpe:  {market_sharpe:+.4f}")
    print(f"   Best Sharpe:    {best_overall['sharpe_ratio']:+.4f}")
    print(f"   AmÃ©lioration:   {improvement:+.2f}%")

print("\n" + "="*80)
print("ANALYSE BASELINE TERMINÃ‰E")
print("="*80)

# Sauvegarder les modÃ¨les
import pickle

print("\nğŸ’¾ Sauvegarde des modÃ¨les...")
with open('lgb_model.pkl', 'wb') as f:
    pickle.dump(lgb_model, f)
print("   âœ“ LightGBM sauvegardÃ©: lgb_model.pkl")

with open('xgb_model.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)
print("   âœ“ XGBoost sauvegardÃ©: xgb_model.pkl")

# Sauvegarder les rÃ©sultats
results_df = pd.DataFrame(all_results_sorted)
results_df.to_csv('baseline_results.csv', index=False)
print("   âœ“ RÃ©sultats sauvegardÃ©s: baseline_results.csv")

print("\nâœ“ Tous les fichiers sauvegardÃ©s!")
print("\nğŸ¯ PROCHAINE Ã‰TAPE: Tester avec l'API Kaggle locale")